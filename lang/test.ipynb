{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependenicas e Variaveis Nessesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage \n",
    "\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate,\n",
    "                                    HumanMessagePromptTemplate,\n",
    "                                    MessagesPlaceholder,\n",
    "                                    PromptTemplate,\n",
    "                                    ChatPromptTemplate)\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory as hist\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./../.env\")\n",
    "\n",
    "parse = StrOutputParser()\n",
    "base_url = \"127.0.0.1:11434\"\n",
    "# chatbot = \"deepseek-r1:1.5b\"\n",
    "chatbot = \"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed =  OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embed.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embed,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type = \"mmr\" , search_kwargs= {'k': 2})\n",
    "\n",
    "retriever.invoke(\"Stealing from the bank is a crime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo :\n",
    "\n",
    "    # Funcao que pega chatprompt que vai pra llm e mandar uma copia para embed\n",
    "\n",
    "    # Funcao que embeddar a resposta da llm\n",
    "\n",
    "    # funcao que grave para vector store (faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Imagine you're trying to describe a picture of a cat. You could say things like \"the cat has whiskers\" or \"the cat is black and white.\" But, if someone asks you what the whiskers are made of, or how the colors got there, you might not be able to explain it in simple terms.\n",
      "\n",
      "That's kind of like what happens when we try to understand images or videos. Our brains can pick up on patterns and features, but sometimes those patterns are hard to put into words.\n",
      "\n",
      "Latent spaces are a way to represent those hidden patterns and features as numbers. Think of them like a secret code that lets computers understand the underlying structure of an image or video.\n",
      "\n",
      "Imagine you have a bunch of different pictures, each with its own unique features (like whiskers, eyes, nose, etc.). When we put all these pictures together into one big database, it's hard to see what makes each picture special. But if we use latent spaces, we can take those pictures and find the common patterns and features that make them similar.\n",
      "\n",
      "For example, you might see a picture of a cat with whiskers and another picture of a dog with ears, both of which are similar to other images in the database. By looking at these similarities and differences, the computer can figure out what makes each image unique (like \"this is a cat\" or \"this is a dog\").\n",
      "\n",
      "Latent spaces help computers understand complex data like images and videos by finding hidden patterns and features that aren't immediately obvious.\n"
     ]
    }
   ],
   "source": [
    "chatter = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=chatbot\n",
    ")\n",
    "# chatter.invoke(\"faz print de hello world em php\").pretty_print()\n",
    "\n",
    "chatter.invoke(\"explain latent spaces using simple terminology.\").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "# human named templates are used to define messages sent from the user\n",
    "_human =  HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "#system named templates are used to define  messages that define the ai role\n",
    "_system = SystemMessagePromptTemplate.from_template(\"Your name is Angel\")\n",
    "#\n",
    "_messages = [_human, MessagesPlaceholder(variable_name='history'), _system]\n",
    "\n",
    "_prompt = ChatPromptTemplate(messages=_messages)\n",
    "\n",
    "chain =  _prompt | chatter | parse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistance is maintainded by langchain through session ids this can be called back through sql queries\n",
    "connection_string = 'sqlite:///vector_store/chat_history.db'\n",
    "def get_session_history(session_id):\n",
    "    return  hist(session_id, connection_string)\n",
    "\n",
    "runnable_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key='input', history_messages_key='history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(session_id, input):\n",
    "    output = runnable_history.invoke(\n",
    "        {'input' : input},\n",
    "        config={'configurable' : {'session_id' : session_id}}\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"celo\"\n",
    "chat_with_llm(user_id, \"explica porque o brasil e tao legal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_session_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# getting history\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mget_session_history\u001b[49m(user_id)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_session_history' is not defined"
     ]
    }
   ],
   "source": [
    "# getting history\n",
    "history = get_session_history(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt templates\n",
    "#templates that can help generate prompts dynamically\n",
    "\n",
    "question_template = HumanMessagePromptTemplate.from_template(\"explain {topic}, using {level} level language\")\n",
    "system_template = SystemMessagePromptTemplate.from_template(\"you are a {prof}. describe things using ideas related to your profession.\")\n",
    "analysis_prompt = ChatPromptTemplate.from_template('''Answer as though you were a small child.\n",
    "                                                   You need to tell me how difficult the text you recieve is to understand.\n",
    "                                                   Answer in one sentence only.\n",
    "                                                   Analyze the following text: {response}\n",
    "                                                   ''')\n",
    "\n",
    "#chat template\n",
    "messages_template = [question_template, system_template]\n",
    "chat_template = ChatPromptTemplate(messages_template)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chains\n",
    "# chains change how things get invoked. \n",
    "#chain uses | to bind a chat template to a model\n",
    "chain = chat_template | chatter | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chaining Runnables.\n",
    "# chain -> new chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#composed chain\n",
    "# {\"variable\" : runnable} | next_runnable\n",
    "\n",
    "# check_bot = {\"response\" : chain} | analysis_prompt | checker | parse\n",
    "\n",
    "# check_chain_response = check_bot.invoke({  \"level\" : \"pdh\",  \"prof\" : \"biologist\", \"topic\":\"soil\"})\n",
    "# print(check_chain_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output parsers are classes that structure the output of information from an llm. this is accomplished through the use of pydantic -base model, field- and PydanticOutputParser. build a class that abstracts the task. you can then use typed variables with fields whose descriptions are natural language tasks. these class properties are passed into the system prompt as formating instructions along with the query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "file_path = r\"D:\\Dev\\langchain\\lang\\steamlit\\splitter\\documents\\artigo.pdf\"\n",
    "loader = PyMuPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'LibreOffice 24.2',\n",
      " 'creator': 'Writer',\n",
      " 'creationdate': '2025-03-04T19:50:50-03:00',\n",
      " 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf',\n",
      " 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf',\n",
      " 'total_pages': 4,\n",
      " 'format': 'PDF 1.7',\n",
      " 'title': '',\n",
      " 'author': '',\n",
      " 'subject': '',\n",
      " 'keywords': '',\n",
      " 'moddate': '',\n",
      " 'trapped': '',\n",
      " 'modDate': '',\n",
      " 'creationDate': \"D:20250304195050-03'00'\",\n",
      " 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steamlit/splitter/documents [] ['artigo.pdf', 'test-IA.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pdfs = []\n",
    "for root, dirs, files in os.walk(\"./steamlit/splitter/documents\"):\n",
    "    print(root, dirs, files)\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdfs.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Sistema de LLM RAG com Dados \\nEmpresariais: Integração de Langchain, React \\ne Django para Comunicação de API\\nResumo\\nEste artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \\nutilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \\nemprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \\ninterface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \\nobjetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \\nde maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \\ne gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \\nescalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \\ndo negócio.\\n1. Introdução\\nNos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \\npotencial para transformar como interagimos com dados empresariais, fornecendo respostas \\ndinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \\nsoluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \\nde RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \\nvez que combinam a recuperação de informações de bases de dados específicas com a capacidade \\nde geração de conteúdo dos LLMs.\\nO objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \\ndados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \\narquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \\natua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é \\nresponsável pela criação da interface de usuário (UI) e Django cria a API de comunicação entre o \\nfront-end e o back-end.\\n2. Arquitetura do Sistema\\n2.1 Langchain para Integração de Modelos de Linguagem com Fontes de Dados\\nLangchain é uma biblioteca Python que facilita a criação de sistemas de IA que utilizam LLMs para \\ntarefas de consulta e geração. Em nosso sistema, Langchain é utilizado para integrar o modelo de \\nlinguagem com os dados empresariais. A biblioteca permite que o modelo acesse dados específicos \\ne realize tarefas de recuperação e geração de maneira eficiente.\\nO processo básico do Langchain em nosso sistema envolve:\\n\\uf0b7Carregamento de Dados Empresariais: Utilização de conectores para diferentes fontes de \\ndados da empresa, como bancos de dados SQL, arquivos CSV ou APIs externas.'), Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='\\uf0b7Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \\nrelevantes para a geração de respostas personalizadas.\\n\\uf0b7Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \\nrespostas mais precisas, adequadas ao contexto empresarial.\\n2.2 Django para Criação da API\\nDjango, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \\nque facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \\nas solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \\nLangchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\\nFuncionalidades da API:\\n\\uf0b7Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \\npermitindo consultas e interações via HTTP.\\n\\uf0b7Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \\nque apenas usuários autorizados possam acessar informações sensíveis.\\n\\uf0b7Integração com Langchain: A API é responsável por fazer a interface entre a camada de \\nfront-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \\nrespostas.\\n2.3 React para Interface de Usuário\\nO React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \\ninterativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \\nque os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\\nFuncionalidades do Front-End:\\n\\uf0b7Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \\ndados empresariais.\\n\\uf0b7Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \\ntempo real.\\n\\uf0b7Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \\nconsultas anteriores, melhorando a experiência do usuário.\\n3. Desenvolvimento do Sistema\\n3.1 Integração de Dados com Langchain\\nA primeira etapa do desenvolvimento foi a integração dos dados empresariais com Langchain. Isso \\nenvolveu a implementação de conectores específicos para as fontes de dados da empresa, como \\nbancos de dados SQL e arquivos CSV. O Langchain foi configurado para fazer consultas a essas \\nfontes e recuperar informações relevantes.\\nA configuração do Langchain permitiu:\\n\\uf0b7A recuperação eficiente de dados com base em palavras-chave ou perguntas específicas.\\n\\uf0b7O uso de modelos de linguagem pré-treinados para gerar respostas contextuais e detalhadas \\ncom base nas informações recuperadas.\\n\\uf0b7A adaptação dos modelos de linguagem para lidar com a terminologia e os dados específicos \\nda empresa.'), Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='3.2 Implementação da API com Django\\nA implementação da API foi realizada utilizando o Django, onde a estrutura de endpoints foi \\norganizada para receber as consultas e enviar as respostas. A API foi configurada para:\\n\\uf0b7Receber as solicitações de consultas via métodos POST.\\n\\uf0b7Processar as consultas e interagir com o Langchain para gerar respostas.\\n\\uf0b7Retornar as respostas geradas para o front-end.\\nAlém disso, foram implementadas autenticação e controle de acesso para garantir a segurança dos \\ndados.\\n3.3 Desenvolvimento do Front-End com React\\nA interface de usuário foi desenvolvida com React para fornecer uma experiência interativa e \\nintuitiva. A aplicação front-end foi configurada para:\\n\\uf0b7Enviar as consultas feitas pelo usuário à API Django.\\n\\uf0b7Exibir as respostas de maneira clara e estruturada.\\n\\uf0b7Fornecer funcionalidades adicionais, como sugestões de perguntas e feedbacks dinâmicos \\npara melhorar a experiência do usuário.\\n4. Resultados\\nApós a implementação, o sistema demonstrou uma melhoria significativa na forma como os \\nfuncionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \\nlinguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \\nusuários a obter insights rápidos e relevantes.\\nA integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \\nsistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \\nmanutenção.\\n5. Conclusões\\nA combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \\nsistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \\nrecuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \\nDjango e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.\\nEste sistema pode ser expandido para lidar com diferentes tipos de dados empresariais e ser \\nadaptado a diversas necessidades organizacionais. A flexibilidade da arquitetura permite que a \\nsolução seja escalada conforme a demanda da empresa, tornando-se uma ferramenta valiosa para \\nempresas que buscam otimizar o acesso e a utilização de seus dados.\\n6. Trabalhos Futuros\\nA pesquisa pode ser expandida para integrar mais fontes de dados, utilizar modelos de linguagem \\nmais avançados, ou incorporar técnicas de aprendizado contínuo para melhorar a precisão das \\nrespostas geradas. Além disso, a implementação de funcionalidades adicionais, como análise de \\nsentimentos ou personalização de respostas, pode ser considerada para aumentar a sofisticação do \\nsistema.'), Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 3}, page_content='')]\n",
      "[Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-16T17:38:50-03:00', 'source': './steamlit/splitter/documents\\\\test-IA.pdf', 'file_path': './steamlit/splitter/documents\\\\test-IA.pdf', 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250316173850-03'00'\", 'page': 0}, page_content='Maria tem 6 abacaxi\\nAna tem 9 melão\\nBruna tem 1 televisão\\nAdriana tem 2 celular')]\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for pdf in pdfs:\n",
    "    loader = PyMuPDFLoader(pdf)\n",
    "    temp = loader.load()\n",
    "    docs.extend(temp)\n",
    "    \n",
    "    print(temp)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(docs):\n",
    "    return '\\n\\n'.join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "context = format_text(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema de LLM RAG com Dados \n",
      "Empresariais: Integração de Langchain, React \n",
      "e Django para Comunicação de API\n",
      "Resumo\n",
      "Este artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \n",
      "utilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \n",
      "emprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \n",
      "interface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \n",
      "objetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \n",
      "de maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \n",
      "e gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \n",
      "escalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \n",
      "do negócio.\n",
      "1. Introdução\n",
      "Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \n",
      "potencial para transformar como interagimos com dados empresariais, fornecendo respostas \n",
      "dinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \n",
      "soluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \n",
      "de RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \n",
      "vez que combinam a recuperação de informações de bases de dados específicas com a capacidade \n",
      "de geração de conteúdo dos LLMs.\n",
      "O objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \n",
      "dados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \n",
      "arquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \n",
      "atua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é \n",
      "responsável pela criação da interface de usuário (UI) e Django cria a API de comunicação entre o \n",
      "front-end e o back-end.\n",
      "2. Arquitetura do Sistema\n",
      "2.1 Langchain para Integração de Modelos de Linguagem com Fontes de Dados\n",
      "Langchain é uma biblioteca Python que facilita a criação de sistemas de IA que utilizam LLMs para \n",
      "tarefas de consulta e geração. Em nosso sistema, Langchain é utilizado para integrar o modelo de \n",
      "linguagem com os dados empresariais. A biblioteca permite que o modelo acesse dados específicos \n",
      "e realize tarefas de recuperação e geração de maneira eficiente.\n",
      "O processo básico do Langchain em nosso sistema envolve:\n",
      "Carregamento de Dados Empresariais: Utilização de conectores para diferentes fontes de \n",
      "dados da empresa, como bancos de dados SQL, arquivos CSV ou APIs externas.\n",
      "\n",
      "Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \n",
      "relevantes para a geração de respostas personalizadas.\n",
      "Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \n",
      "respostas mais precisas, adequadas ao contexto empresarial.\n",
      "2.2 Django para Criação da API\n",
      "Django, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \n",
      "que facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \n",
      "as solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \n",
      "Langchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\n",
      "Funcionalidades da API:\n",
      "Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \n",
      "permitindo consultas e interações via HTTP.\n",
      "Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \n",
      "que apenas usuários autorizados possam acessar informações sensíveis.\n",
      "Integração com Langchain: A API é responsável por fazer a interface entre a camada de \n",
      "front-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \n",
      "respostas.\n",
      "2.3 React para Interface de Usuário\n",
      "O React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \n",
      "interativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \n",
      "que os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\n",
      "Funcionalidades do Front-End:\n",
      "Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \n",
      "dados empresariais.\n",
      "Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \n",
      "tempo real.\n",
      "Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \n",
      "consultas anteriores, melhorando a experiência do usuário.\n",
      "3. Desenvolvimento do Sistema\n",
      "3.1 Integração de Dados com Langchain\n",
      "A primeira etapa do desenvolvimento foi a integração dos dados empresariais com Langchain. Isso \n",
      "envolveu a implementação de conectores específicos para as fontes de dados da empresa, como \n",
      "bancos de dados SQL e arquivos CSV. O Langchain foi configurado para fazer consultas a essas \n",
      "fontes e recuperar informações relevantes.\n",
      "A configuração do Langchain permitiu:\n",
      "A recuperação eficiente de dados com base em palavras-chave ou perguntas específicas.\n",
      "O uso de modelos de linguagem pré-treinados para gerar respostas contextuais e detalhadas \n",
      "com base nas informações recuperadas.\n",
      "A adaptação dos modelos de linguagem para lidar com a terminologia e os dados específicos \n",
      "da empresa.\n",
      "\n",
      "3.2 Implementação da API com Django\n",
      "A implementação da API foi realizada utilizando o Django, onde a estrutura de endpoints foi \n",
      "organizada para receber as consultas e enviar as respostas. A API foi configurada para:\n",
      "Receber as solicitações de consultas via métodos POST.\n",
      "Processar as consultas e interagir com o Langchain para gerar respostas.\n",
      "Retornar as respostas geradas para o front-end.\n",
      "Além disso, foram implementadas autenticação e controle de acesso para garantir a segurança dos \n",
      "dados.\n",
      "3.3 Desenvolvimento do Front-End com React\n",
      "A interface de usuário foi desenvolvida com React para fornecer uma experiência interativa e \n",
      "intuitiva. A aplicação front-end foi configurada para:\n",
      "Enviar as consultas feitas pelo usuário à API Django.\n",
      "Exibir as respostas de maneira clara e estruturada.\n",
      "Fornecer funcionalidades adicionais, como sugestões de perguntas e feedbacks dinâmicos \n",
      "para melhorar a experiência do usuário.\n",
      "4. Resultados\n",
      "Após a implementação, o sistema demonstrou uma melhoria significativa na forma como os \n",
      "funcionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \n",
      "linguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \n",
      "usuários a obter insights rápidos e relevantes.\n",
      "A integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \n",
      "sistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \n",
      "manutenção.\n",
      "5. Conclusões\n",
      "A combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \n",
      "sistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \n",
      "recuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \n",
      "Django e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.\n",
      "Este sistema pode ser expandido para lidar com diferentes tipos de dados empresariais e ser \n",
      "adaptado a diversas necessidades organizacionais. A flexibilidade da arquitetura permite que a \n",
      "solução seja escalada conforme a demanda da empresa, tornando-se uma ferramenta valiosa para \n",
      "empresas que buscam otimizar o acesso e a utilização de seus dados.\n",
      "6. Trabalhos Futuros\n",
      "A pesquisa pode ser expandida para integrar mais fontes de dados, utilizar modelos de linguagem \n",
      "mais avançados, ou incorporar técnicas de aprendizado contínuo para melhorar a precisão das \n",
      "respostas geradas. Além disso, a implementação de funcionalidades adicionais, como análise de \n",
      "sentimentos ou personalização de respostas, pode ser considerada para aumentar a sofisticação do \n",
      "sistema.\n",
      "\n",
      "\n",
      "\n",
      "Maria tem 6 abacaxi\n",
      "Ana tem 9 melão\n",
      "Bruna tem 1 televisão\n",
      "Adriana tem 2 celular\n"
     ]
    }
   ],
   "source": [
    "# check of token size of docs\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Sistema de LLM RAG com Dados \\nEmpresariais: Integração de Langchain, React \\ne Django para Comunicação de API\\nResumo\\nEste artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \\nutilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \\nemprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \\ninterface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \\nobjetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \\nde maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \\ne gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \\nescalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \\ndo negócio.\\n1. Introdução\\nNos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \\npotencial para transformar como interagimos com dados empresariais, fornecendo respostas \\ndinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \\nsoluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \\nde RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \\nvez que combinam a recuperação de informações de bases de dados específicas com a capacidade \\nde geração de conteúdo dos LLMs.\\nO objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \\ndados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \\narquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \\natua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='atua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é \\nresponsável pela criação da interface de usuário (UI) e Django cria a API de comunicação entre o \\nfront-end e o back-end.\\n2. Arquitetura do Sistema\\n2.1 Langchain para Integração de Modelos de Linguagem com Fontes de Dados\\nLangchain é uma biblioteca Python que facilita a criação de sistemas de IA que utilizam LLMs para \\ntarefas de consulta e geração. Em nosso sistema, Langchain é utilizado para integrar o modelo de \\nlinguagem com os dados empresariais. A biblioteca permite que o modelo acesse dados específicos \\ne realize tarefas de recuperação e geração de maneira eficiente.\\nO processo básico do Langchain em nosso sistema envolve:\\n\\uf0b7Carregamento de Dados Empresariais: Utilização de conectores para diferentes fontes de \\ndados da empresa, como bancos de dados SQL, arquivos CSV ou APIs externas.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='\\uf0b7Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \\nrelevantes para a geração de respostas personalizadas.\\n\\uf0b7Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \\nrespostas mais precisas, adequadas ao contexto empresarial.\\n2.2 Django para Criação da API\\nDjango, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \\nque facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \\nas solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \\nLangchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\\nFuncionalidades da API:\\n\\uf0b7Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \\npermitindo consultas e interações via HTTP.\\n\\uf0b7Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \\nque apenas usuários autorizados possam acessar informações sensíveis.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='que apenas usuários autorizados possam acessar informações sensíveis.\\n\\uf0b7Integração com Langchain: A API é responsável por fazer a interface entre a camada de \\nfront-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \\nrespostas.\\n2.3 React para Interface de Usuário\\nO React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \\ninterativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \\nque os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\\nFuncionalidades do Front-End:\\n\\uf0b7Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \\ndados empresariais.\\n\\uf0b7Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \\ntempo real.\\n\\uf0b7Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \\nconsultas anteriores, melhorando a experiência do usuário.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='consultas anteriores, melhorando a experiência do usuário.\\n3. Desenvolvimento do Sistema\\n3.1 Integração de Dados com Langchain\\nA primeira etapa do desenvolvimento foi a integração dos dados empresariais com Langchain. Isso \\nenvolveu a implementação de conectores específicos para as fontes de dados da empresa, como \\nbancos de dados SQL e arquivos CSV. O Langchain foi configurado para fazer consultas a essas \\nfontes e recuperar informações relevantes.\\nA configuração do Langchain permitiu:\\n\\uf0b7A recuperação eficiente de dados com base em palavras-chave ou perguntas específicas.\\n\\uf0b7O uso de modelos de linguagem pré-treinados para gerar respostas contextuais e detalhadas \\ncom base nas informações recuperadas.\\n\\uf0b7A adaptação dos modelos de linguagem para lidar com a terminologia e os dados específicos \\nda empresa.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='3.2 Implementação da API com Django\\nA implementação da API foi realizada utilizando o Django, onde a estrutura de endpoints foi \\norganizada para receber as consultas e enviar as respostas. A API foi configurada para:\\n\\uf0b7Receber as solicitações de consultas via métodos POST.\\n\\uf0b7Processar as consultas e interagir com o Langchain para gerar respostas.\\n\\uf0b7Retornar as respostas geradas para o front-end.\\nAlém disso, foram implementadas autenticação e controle de acesso para garantir a segurança dos \\ndados.\\n3.3 Desenvolvimento do Front-End com React\\nA interface de usuário foi desenvolvida com React para fornecer uma experiência interativa e \\nintuitiva. A aplicação front-end foi configurada para:\\n\\uf0b7Enviar as consultas feitas pelo usuário à API Django.\\n\\uf0b7Exibir as respostas de maneira clara e estruturada.\\n\\uf0b7Fornecer funcionalidades adicionais, como sugestões de perguntas e feedbacks dinâmicos \\npara melhorar a experiência do usuário.\\n4. Resultados'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='para melhorar a experiência do usuário.\\n4. Resultados\\nApós a implementação, o sistema demonstrou uma melhoria significativa na forma como os \\nfuncionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \\nlinguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \\nusuários a obter insights rápidos e relevantes.\\nA integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \\nsistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \\nmanutenção.\\n5. Conclusões\\nA combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \\nsistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \\nrecuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \\nDjango e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='Django e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.\\nEste sistema pode ser expandido para lidar com diferentes tipos de dados empresariais e ser \\nadaptado a diversas necessidades organizacionais. A flexibilidade da arquitetura permite que a \\nsolução seja escalada conforme a demanda da empresa, tornando-se uma ferramenta valiosa para \\nempresas que buscam otimizar o acesso e a utilização de seus dados.\\n6. Trabalhos Futuros\\nA pesquisa pode ser expandida para integrar mais fontes de dados, utilizar modelos de linguagem \\nmais avançados, ou incorporar técnicas de aprendizado contínuo para melhorar a precisão das \\nrespostas geradas. Além disso, a implementação de funcionalidades adicionais, como análise de \\nsentimentos ou personalização de respostas, pode ser considerada para aumentar a sofisticação do \\nsistema.'),\n",
      " Document(metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-16T17:38:50-03:00', 'source': './steamlit/splitter/documents\\\\test-IA.pdf', 'file_path': './steamlit/splitter/documents\\\\test-IA.pdf', 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250316173850-03'00'\", 'page': 0}, page_content='Maria tem 6 abacaxi\\nAna tem 9 melão\\nBruna tem 1 televisão\\nAdriana tem 2 celular')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104264,\n",
       " 334,\n",
       " 451,\n",
       " 19641,\n",
       " 460,\n",
       " 2971,\n",
       " 452,\n",
       " 141520,\n",
       " 793,\n",
       " 24156,\n",
       " 430,\n",
       " 6477,\n",
       " 276,\n",
       " 25,\n",
       " 89184,\n",
       " 23267,\n",
       " 1747,\n",
       " 334,\n",
       " 27830,\n",
       " 13289,\n",
       " 11,\n",
       " 6184,\n",
       " 793,\n",
       " 68,\n",
       " 121538,\n",
       " 1209,\n",
       " 146498,\n",
       " 334,\n",
       " 10328,\n",
       " 198,\n",
       " 179818,\n",
       " 198,\n",
       " 26237,\n",
       " 45084,\n",
       " 161800,\n",
       " 737,\n",
       " 293,\n",
       " 37784,\n",
       " 334,\n",
       " 1713,\n",
       " 12767,\n",
       " 334,\n",
       " 2317,\n",
       " 22686,\n",
       " 355,\n",
       " 180246,\n",
       " 334,\n",
       " 499,\n",
       " 31798,\n",
       " 350,\n",
       " 49,\n",
       " 2971,\n",
       " 8,\n",
       " 793,\n",
       " 2056,\n",
       " 52248,\n",
       " 39564,\n",
       " 334,\n",
       " 108504,\n",
       " 350,\n",
       " 7454,\n",
       " 25153,\n",
       " 8,\n",
       " 452,\n",
       " 24315,\n",
       " 97292,\n",
       " 334,\n",
       " 3030,\n",
       " 13596,\n",
       " 13,\n",
       " 355,\n",
       " 71507,\n",
       " 793,\n",
       " 7175,\n",
       " 42989,\n",
       " 27830,\n",
       " 13289,\n",
       " 1209,\n",
       " 144517,\n",
       " 334,\n",
       " 39564,\n",
       " 334,\n",
       " 108504,\n",
       " 452,\n",
       " 115142,\n",
       " 334,\n",
       " 24315,\n",
       " 11,\n",
       " 6184,\n",
       " 1209,\n",
       " 261,\n",
       " 793,\n",
       " 11132,\n",
       " 334,\n",
       " 67663,\n",
       " 319,\n",
       " 121538,\n",
       " 1209,\n",
       " 44999,\n",
       " 261,\n",
       " 10328,\n",
       " 334,\n",
       " 63586,\n",
       " 3853,\n",
       " 293,\n",
       " 5567,\n",
       " 18507,\n",
       " 319,\n",
       " 293,\n",
       " 1602,\n",
       " 18507,\n",
       " 13,\n",
       " 532,\n",
       " 793,\n",
       " 61436,\n",
       " 4330,\n",
       " 28924,\n",
       " 12767,\n",
       " 1212,\n",
       " 59290,\n",
       " 661,\n",
       " 1994,\n",
       " 73354,\n",
       " 90153,\n",
       " 73071,\n",
       " 24315,\n",
       " 8430,\n",
       " 6477,\n",
       " 276,\n",
       " 97292,\n",
       " 793,\n",
       " 613,\n",
       " 39477,\n",
       " 75394,\n",
       " 319,\n",
       " 80759,\n",
       " 11,\n",
       " 54002,\n",
       " 1713,\n",
       " 23255,\n",
       " 334,\n",
       " 108504,\n",
       " 38947,\n",
       " 334,\n",
       " 127660,\n",
       " 11,\n",
       " 155881,\n",
       " 793,\n",
       " 68,\n",
       " 105355,\n",
       " 112638,\n",
       " 3832,\n",
       " 48777,\n",
       " 3611,\n",
       " 3921,\n",
       " 863,\n",
       " 28533,\n",
       " 8430,\n",
       " 6477,\n",
       " 276,\n",
       " 13,\n",
       " 355,\n",
       " 171940,\n",
       " 52153,\n",
       " 1212,\n",
       " 793,\n",
       " 268,\n",
       " 5842,\n",
       " 15759,\n",
       " 11,\n",
       " 61198,\n",
       " 319,\n",
       " 133084,\n",
       " 11,\n",
       " 160902,\n",
       " 261,\n",
       " 21590,\n",
       " 153582,\n",
       " 319,\n",
       " 38082,\n",
       " 73018,\n",
       " 45547,\n",
       " 472,\n",
       " 73212,\n",
       " 793,\n",
       " 2408,\n",
       " 65658,\n",
       " 558,\n",
       " 16,\n",
       " 13,\n",
       " 63470,\n",
       " 1747,\n",
       " 198,\n",
       " 40136,\n",
       " 30517,\n",
       " 11680,\n",
       " 11,\n",
       " 1994,\n",
       " 8186,\n",
       " 365,\n",
       " 334,\n",
       " 126554,\n",
       " 8551,\n",
       " 334,\n",
       " 30174,\n",
       " 19126,\n",
       " 2528,\n",
       " 350,\n",
       " 7454,\n",
       " 25153,\n",
       " 8,\n",
       " 31927,\n",
       " 10792,\n",
       " 1064,\n",
       " 10094]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(chunks[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "base_url = \"127.0.0.1:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\", base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embeddings.embed_query(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(len(vector))\n",
    "index.ntotal, index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store= FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"what is RAG?\"\n",
    "docs = vector_store.search(query=q,k=5,search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f6707d51-3314-4440-a623-a87353670590', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Sistema de LLM RAG com Dados \\nEmpresariais: Integração de Langchain, React \\ne Django para Comunicação de API\\nResumo\\nEste artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \\nutilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \\nemprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \\ninterface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \\nobjetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \\nde maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \\ne gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \\nescalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \\ndo negócio.\\n1. Introdução\\nNos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande'),\n",
       " Document(id='9bd2ec71-994e-4c97-a77a-ff405cbbb7d8', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \\npotencial para transformar como interagimos com dados empresariais, fornecendo respostas \\ndinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \\nsoluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \\nde RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \\nvez que combinam a recuperação de informações de bases de dados específicas com a capacidade \\nde geração de conteúdo dos LLMs.\\nO objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \\ndados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \\narquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \\natua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é'),\n",
       " Document(id='24b710a1-d294-4b05-acad-8f4229a91e61', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='para melhorar a experiência do usuário.\\n4. Resultados\\nApós a implementação, o sistema demonstrou uma melhoria significativa na forma como os \\nfuncionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \\nlinguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \\nusuários a obter insights rápidos e relevantes.\\nA integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \\nsistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \\nmanutenção.\\n5. Conclusões\\nA combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \\nsistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \\nrecuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \\nDjango e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.'),\n",
       " Document(id='8937afee-88dd-4555-82c8-1fb2395655cb', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='\\uf0b7Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \\nrelevantes para a geração de respostas personalizadas.\\n\\uf0b7Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \\nrespostas mais precisas, adequadas ao contexto empresarial.\\n2.2 Django para Criação da API\\nDjango, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \\nque facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \\nas solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \\nLangchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\\nFuncionalidades da API:\\n\\uf0b7Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \\npermitindo consultas e interações via HTTP.\\n\\uf0b7Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \\nque apenas usuários autorizados possam acessar informações sensíveis.'),\n",
       " Document(id='5fdfcd3c-7415-4427-9f04-ec3375138efb', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': './steamlit/splitter/documents\\\\artigo.pdf', 'file_path': './steamlit/splitter/documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='que apenas usuários autorizados possam acessar informações sensíveis.\\n\\uf0b7Integração com Langchain: A API é responsável por fazer a interface entre a camada de \\nfront-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \\nrespostas.\\n2.3 React para Interface de Usuário\\nO React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \\ninterativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \\nque os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\\nFuncionalidades do Front-End:\\n\\uf0b7Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \\ndados empresariais.\\n\\uf0b7Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \\ntempo real.\\n\\uf0b7Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \\nconsultas anteriores, melhorando a experiência do usuário.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "base_url = \"127.0.0.1:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\", base_url=base_url)\n",
    "db_path = r\"D:\\Dev\\langchain\\lang\\steamlit\\vector_db\"\n",
    "db_name = \"cerebro\"\n",
    "vector_store.save_local(folder_path=db_path,index_name=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vectore_store = FAISS.load_local(db_path, embeddings, db_name,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='dce52bea-0703-4191-80e1-29836c676d6d', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Sistema de LLM RAG com Dados \\nEmpresariais: Integração de Langchain, React \\ne Django para Comunicação de API\\nResumo\\nEste artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \\nutilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \\nemprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \\ninterface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \\nobjetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \\nde maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \\ne gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \\nescalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \\ndo negócio.\\n1. Introdução\\nNos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande'),\n",
       " Document(id='0451e637-f5fc-4664-9fa9-34e0e947d2f3', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \\npotencial para transformar como interagimos com dados empresariais, fornecendo respostas \\ndinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \\nsoluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \\nde RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \\nvez que combinam a recuperação de informações de bases de dados específicas com a capacidade \\nde geração de conteúdo dos LLMs.\\nO objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \\ndados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \\narquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \\natua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é'),\n",
       " Document(id='62605ddd-4703-49c2-86ae-f0babc20b520', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='para melhorar a experiência do usuário.\\n4. Resultados\\nApós a implementação, o sistema demonstrou uma melhoria significativa na forma como os \\nfuncionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \\nlinguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \\nusuários a obter insights rápidos e relevantes.\\nA integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \\nsistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \\nmanutenção.\\n5. Conclusões\\nA combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \\nsistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \\nrecuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \\nDjango e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.'),\n",
       " Document(id='af980aad-6f90-4f6d-8c56-aefdebc4f061', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='\\uf0b7Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \\nrelevantes para a geração de respostas personalizadas.\\n\\uf0b7Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \\nrespostas mais precisas, adequadas ao contexto empresarial.\\n2.2 Django para Criação da API\\nDjango, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \\nque facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \\nas solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \\nLangchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\\nFuncionalidades da API:\\n\\uf0b7Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \\npermitindo consultas e interações via HTTP.\\n\\uf0b7Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \\nque apenas usuários autorizados possam acessar informações sensíveis.'),\n",
       " Document(id='b284e474-a629-479e-bf38-977bb7e737c5', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 1}, page_content='que apenas usuários autorizados possam acessar informações sensíveis.\\n\\uf0b7Integração com Langchain: A API é responsável por fazer a interface entre a camada de \\nfront-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \\nrespostas.\\n2.3 React para Interface de Usuário\\nO React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \\ninterativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \\nque os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\\nFuncionalidades do Front-End:\\n\\uf0b7Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \\ndados empresariais.\\n\\uf0b7Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \\ntempo real.\\n\\uf0b7Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \\nconsultas anteriores, melhorando a experiência do usuário.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"what is RAG?\"\n",
    "docs = _vectore_store.search(query=q,k=5,search_type=\"similarity\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='dce52bea-0703-4191-80e1-29836c676d6d', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Sistema de LLM RAG com Dados \\nEmpresariais: Integração de Langchain, React \\ne Django para Comunicação de API\\nResumo\\nEste artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \\nutilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \\nemprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \\ninterface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \\nobjetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \\nde maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \\ne gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \\nescalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \\ndo negócio.\\n1. Introdução\\nNos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande'),\n",
       " Document(id='0451e637-f5fc-4664-9fa9-34e0e947d2f3', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 0}, page_content='Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \\npotencial para transformar como interagimos com dados empresariais, fornecendo respostas \\ndinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \\nsoluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \\nde RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \\nvez que combinam a recuperação de informações de bases de dados específicas com a capacidade \\nde geração de conteúdo dos LLMs.\\nO objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \\ndados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \\narquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \\natua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é'),\n",
       " Document(id='62605ddd-4703-49c2-86ae-f0babc20b520', metadata={'producer': 'LibreOffice 24.2', 'creator': 'Writer', 'creationdate': '2025-03-04T19:50:50-03:00', 'source': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'file_path': 'D:\\\\Dev\\\\langchain\\\\lang\\\\steamlit\\\\splitter\\\\documents\\\\artigo.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250304195050-03'00'\", 'page': 2}, page_content='para melhorar a experiência do usuário.\\n4. Resultados\\nApós a implementação, o sistema demonstrou uma melhoria significativa na forma como os \\nfuncionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \\nlinguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \\nusuários a obter insights rápidos e relevantes.\\nA integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \\nsistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \\nmanutenção.\\n5. Conclusões\\nA combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \\nsistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \\nrecuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \\nDjango e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = _vectore_store.as_retriever(search_type = \"mmr\", search_kwargs= {'k':3, 'fetch_k': 20, 'lambda_mult': 1})\n",
    "retriever.invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = chatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema de LLM RAG com Dados \n",
      "Empresariais: Integração de Langchain, React \n",
      "e Django para Comunicação de API\n",
      "Resumo\n",
      "Este artigo descreve o desenvolvimento de um sistema de Resposta Através de Geração (RAG) \n",
      "utilizando modelos de linguagem (LLMs) com dados específicos de uma empresa. A solução \n",
      "emprega Langchain para integração de modelos de linguagem com fontes de dados, React para a \n",
      "interface de usuário e Django para criar a API de comunicação entre o front-end e o back-end. O \n",
      "objetivo deste sistema é permitir que os usuários possam consultar dados empresariais específicos \n",
      "de maneira eficiente e inteligente, utilizando um modelo de linguagem capaz de acessar, interpretar \n",
      "e gerar respostas personalizadas baseadas em informações empresariais. A arquitetura proposta é \n",
      "escalável, modular e integrada, permitindo a fácil expansão e adaptação conforme as necessidades \n",
      "do negócio.\n",
      "1. Introdução\n",
      "Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande\n",
      "\n",
      "Nos últimos anos, os Modelos de Linguagem de Grande Escala (LLMs) têm demonstrado grande \n",
      "potencial para transformar como interagimos com dados empresariais, fornecendo respostas \n",
      "dinâmicas e interativas. No entanto, a aplicação desses modelos em contextos corporativos exigia \n",
      "soluções que integrassem dados empresariais com a geração de respostas baseadas em IA. Sistemas \n",
      "de RAG (Retrieval-Augmented Generation) se mostraram eficientes para esse tipo de tarefa, uma \n",
      "vez que combinam a recuperação de informações de bases de dados específicas com a capacidade \n",
      "de geração de conteúdo dos LLMs.\n",
      "O objetivo deste artigo é apresentar um sistema que utiliza LLMs no formato RAG para processar \n",
      "dados empresariais de uma empresa e gerar respostas relevantes e contextualizadas. Para isso, a \n",
      "arquitetura do sistema envolve três componentes principais: Langchain, React e Django. Langchain \n",
      "atua como a interface entre os modelos de linguagem e as fontes de dados, enquanto React é\n",
      "\n",
      "para melhorar a experiência do usuário.\n",
      "4. Resultados\n",
      "Após a implementação, o sistema demonstrou uma melhoria significativa na forma como os \n",
      "funcionários da empresa acessam e interagem com os dados. As respostas geradas pelo modelo de \n",
      "linguagem, com o auxílio de Langchain, foram altamente precisas e contextuais, ajudando os \n",
      "usuários a obter insights rápidos e relevantes.\n",
      "A integração entre Langchain, Django e React provou ser uma solução eficaz para a criação de \n",
      "sistemas de consulta inteligente a dados empresariais, com boa escalabilidade e facilidade de \n",
      "manutenção.\n",
      "5. Conclusões\n",
      "A combinação de Langchain, Django e React oferece uma solução poderosa para a construção de \n",
      "sistemas de Resposta Através de Geração (RAG) com dados empresariais. O uso de LLMs para \n",
      "recuperar e gerar respostas específicas, combinado com a arquitetura robusta proporcionada pelo \n",
      "Django e a interface interativa do React, cria uma experiência de usuário eficiente e intuitiva.\n",
      "\n",
      "Consulta ao Modelo de Linguagem: Langchain permite que o modelo acesse informações \n",
      "relevantes para a geração de respostas personalizadas.\n",
      "Personalização da Resposta: O modelo utiliza as informações recuperadas para gerar \n",
      "respostas mais precisas, adequadas ao contexto empresarial.\n",
      "2.2 Django para Criação da API\n",
      "Django, um framework robusto para o desenvolvimento de back-end, é utilizado para criar a API \n",
      "que facilita a comunicação entre o front-end (React) e o back-end. A API é responsável por receber \n",
      "as solicitações de consulta feitas pelos usuários através do front-end, processá-las, interagir com \n",
      "Langchain para recuperar ou gerar dados e retornar uma resposta para o usuário.\n",
      "Funcionalidades da API:\n",
      "Endpoints RESTful: A API fornece endpoints RESTful para interagir com o sistema, \n",
      "permitindo consultas e interações via HTTP.\n",
      "Autenticação e Autorização: A API implementa mecanismos de autenticação, garantindo \n",
      "que apenas usuários autorizados possam acessar informações sensíveis.\n",
      "\n",
      "que apenas usuários autorizados possam acessar informações sensíveis.\n",
      "Integração com Langchain: A API é responsável por fazer a interface entre a camada de \n",
      "front-end e a camada de IA, utilizando Langchain para a recuperação de dados e geração de \n",
      "respostas.\n",
      "2.3 React para Interface de Usuário\n",
      "O React é utilizado para desenvolver a interface de usuário (UI), proporcionando uma experiência \n",
      "interativa e dinâmica. A aplicação front-end se comunica com a API Django via HTTP, permitindo \n",
      "que os usuários façam consultas aos dados empresariais e recebam respostas de maneira eficiente.\n",
      "Funcionalidades do Front-End:\n",
      "Tela de Consulta: Interface onde os usuários podem fazer perguntas ou solicitações de \n",
      "dados empresariais.\n",
      "Exibição de Respostas: As respostas geradas pela IA são exibidas na UI, com feedback em \n",
      "tempo real.\n",
      "Interatividade: Utilização de recursos como autocompletar e sugestões baseadas nas \n",
      "consultas anteriores, melhorando a experiência do usuário.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_prompt = \"\"\"Anwer from context provided only. If you don't have the information to answer a question, say 'I don't know'. \n",
    "### Context:\n",
    "{context}\n",
    "### Question:\n",
    "{question}\n",
    "### Answer\"\"\"\n",
    "\n",
    "def d(docs):\n",
    "   return '\\n\\n'.join([doc.page_content for doc in docs])  \n",
    "\n",
    "print(d(docs))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m(docs)\n\u001b[0;32m      2\u001b[0m context\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "context = d(docs)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "_prompt = \"\"\"Anwer from context provided only. If you don't have the information to answer a question, say 'I don't know'. \n",
    "### Context:\n",
    "{context}\n",
    "### Question:\n",
    "{question}\n",
    "### Answer\"\"\"\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"You're a helpful assistance ready to answer in a calm and hospitible tone.\")\n",
    "human = HumanMessagePromptTemplate.from_template(_prompt)\n",
    "\n",
    "messages = [system, human]\n",
    "\n",
    "prompt = ChatPromptTemplate(messages)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\" : retriever|d, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is RAG?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RAG significa Retrieval-Augmented Generation, um sistema que combina a '\n",
      " 'recuperação de informações de bases de dados específicas com a capacidade de '\n",
      " 'geração de conteúdo de Modelos de Linguagem (LLMs).')\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
